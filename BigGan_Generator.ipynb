{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":737475,"sourceType":"datasetVersion","datasetId":379764}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport datetime\nimport pandas as pd\nimport random\n\nfrom matplotlib import pyplot as plt\n\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Conv2DTranspose, Reshape, UpSampling2D, LeakyReLU, LayerNormalization, Add\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.optimizers import Adam\n\n\nfrom tensorflow.keras import layers\nimport tensorflow as tf\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n\n\ndef plot_losses(history):\n    plt.rcParams['figure.figsize'] = [20, 5]\n    f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n\n    ax1.set_title('Losses')\n    ax1.set_xlabel('epoch')\n    ax1.legend(loc=\"upper right\")\n    ax1.grid()\n    ax1.plot(history['loss'], label='Training loss')\n    ax1.plot(history['val_loss'], label='Validation loss')\n    ax1.legend()\n\n    ax2.set_title('Accuracy')\n    ax2.set_xlabel('epoch')\n    ax2.legend(loc=\"upper right\")\n    ax2.grid()\n    ax2.plot(history['accuracy'], label='Training accuracy')\n    ax2.plot(history['val_accuracy'], label='Validation accuracy')\n    ax2.legend()\n\n    plt.show()\n\ndef plot_resultados(model, carpeta, height=64, width=64, n=4):\n    \"\"\"\n    Muestra comparaciones entre imágenes originales y reconstruidas por el autoencoder.\n    \"\"\"\n    # Seleccionar imágenes aleatorias\n    archivos = os.listdir(carpeta)\n    archivos_img = random.sample(archivos, n)\n\n    # Cargar y normalizar las imágenes\n    imgs_originales = []\n    for nombre in archivos_img:\n        img = load_img(os.path.join(carpeta, nombre), target_size=(height, width))\n        img_array = img_to_array(img) / 255.0  # normalizar a [0,1]\n        imgs_originales.append(img_array)\n\n    imgs_originales = np.array(imgs_originales)\n\n    # Reconstruir con el modelo\n    imgs_reconstruidas = model.predict(imgs_originales)\n\n    # Mostrar resultados\n    plt.figure(figsize=(12, 6))\n    for i in range(n):\n        # Imagen original\n        ax = plt.subplot(2, n, i + 1)\n        plt.imshow(imgs_originales[i])\n        ax.set_title(\"Original\")\n        ax.axis(\"off\")\n\n        # Imagen reconstruida\n        ax = plt.subplot(2, n, i + 1 + n)\n        plt.imshow(imgs_reconstruidas[i])\n        ax.set_title(\"Reconstruida\")\n        ax.axis(\"off\")\n\n    plt.tight_layout()\n    plt.show()\n\n\ndef mostrar_imagenes_generadas(modelo_generador, latent_dim=100, num_imagenes=4, image_size=(64, 64, 3)):\n    \"\"\"\n    Genera y muestra imágenes lado a lado usando un modelo generador.\n\n    Args:\n        modelo_generador: modelo Keras que recibe un vector latente y devuelve una imagen.\n        latent_dim: dimensión del vector latente.\n        num_imagenes: número de imágenes a generar.\n        image_size: tamaño esperado de las imágenes (solo usado si quieres validar forma).\n    \"\"\"\n    # Generar vectores latentes aleatorios\n    z = generateLatentDim(latent_dim, num_imagenes)\n\n    # Generar imágenes con el modelo\n    imagenes = modelo_generador.predict(z)\n\n    # Mostrar imágenes en una fila\n    fig, axes = plt.subplots(1, num_imagenes, figsize=(num_imagenes * 3, 3))\n    for i, ax in enumerate(axes):\n        ax.imshow((imagenes[i] + 1) / 2)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()\n\ndef generar_imagenes(modelo_generador, latent_dim=100, num_imagenes=4):\n    \"\"\"\n    Genera imágenes en escala de grises usando un modelo generador y OpenCV.\n\n    Args:\n        modelo_generador: modelo Keras que recibe un vector latente y devuelve una imagen.\n        latent_dim: dimensión del vector latente.\n        num_imagenes: número de imágenes a generar.\n\n    Returns:\n        Array de imágenes en escala de grises con forma (num_imagenes, alto, ancho).\n    \"\"\"\n    # Generar vectores latentes aleatorios\n    z = np.random.normal(0, 1, (num_imagenes, latent_dim))\n\n    # Generar imágenes con el modelo\n    imagenes_rgb = modelo_generador.predict(z)\n\n    # Asegurar que las imágenes están en el rango [0, 255] y tipo uint8\n    imagenes_rgb = (imagenes_rgb * 255).astype(np.uint8)\n\n    # Convertir a escala de grises con OpenCV\n    imagenes_grises = np.array([cv2.cvtColor(imagen, cv2.COLOR_RGB2GRAY) for imagen in imagenes_rgb])\n\n    return imagenes_grises\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-26T11:34:08.970898Z","iopub.execute_input":"2025-10-26T11:34:08.971127Z","iopub.status.idle":"2025-10-26T11:34:25.237922Z","shell.execute_reply.started":"2025-10-26T11:34:08.971103Z","shell.execute_reply":"2025-10-26T11:34:25.237329Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# GAN","metadata":{}},{"cell_type":"markdown","source":"## Defining Hiperparameters","metadata":{}},{"cell_type":"code","source":"import os\n\nos.listdir(\"/kaggle/input\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T11:34:25.239106Z","iopub.execute_input":"2025-10-26T11:34:25.239671Z","iopub.status.idle":"2025-10-26T11:34:25.248403Z","shell.execute_reply.started":"2025-10-26T11:34:25.239650Z","shell.execute_reply":"2025-10-26T11:34:25.247615Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"height, width = 64, 64 # Image size, to fit in the competition size\nimage_dir = '/kaggle/input'\nfolder = None\n\nlatent_dim_size = 100\nbatch_size = 128","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T11:34:25.249179Z","iopub.execute_input":"2025-10-26T11:34:25.249421Z","iopub.status.idle":"2025-10-26T11:34:25.412846Z","shell.execute_reply.started":"2025-10-26T11:34:25.249399Z","shell.execute_reply":"2025-10-26T11:34:25.412144Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Latent dim generator\ndef generateLatentDim(latent_dim_size=latent_dim_size, batch_size= batch_size):\n    return np.random.randn(batch_size, latent_dim_size)\n\ndef build_discriminator(img_shape=(64, 64, 3)):\n    img_input = Input(shape=img_shape, name=\"image_input\")\n\n    # 64x64 -> 32x32\n    x = Conv2D(64, kernel_size=3, strides=2, padding='same')(img_input)\n    x = LeakyReLU(0.2)(x)\n\n    # 32x32 -> 16x16\n    x = Conv2D(128, kernel_size=3, strides=2, padding='same')(x)\n    x = LeakyReLU(0.2)(x)\n\n    # 16x16 -> 8x8\n    x = Conv2D(256, kernel_size=3, strides=2, padding='same')(x)\n    x = LeakyReLU(0.2)(x)\n    x = Dropout(0.3)(x)\n\n    # 8x8 -> 4x4\n    x = Conv2D(512, kernel_size=3, strides=2, padding='same')(x)\n    x = LeakyReLU(0.2)(x)\n    x = Dropout(0.3)(x)\n\n    # Clasificación final\n    x = Flatten()(x)\n    out = Dense(1, activation='sigmoid')(x)\n\n    return keras.Model(img_input, out, name=\"Discriminator\")\n\n\ndef build_generator(latent_dim=100, channels=3):\n    z = Input(shape=(latent_dim,), name=\"latent_vector\")\n\n    x = Dense(512 * 8 * 8)(z)\n    x = Reshape((8, 8, 512))(x)\n    x = LeakyReLU(0.2)(x)\n\n    # 8x8 -> 16x16\n    x = Conv2DTranspose(256, kernel_size=3, strides=2, padding='same')(x)\n    x = LayerNormalization()(x)\n    x = LeakyReLU(0.2)(x)\n\n    # 16x16 -> 32x32\n    x = Conv2DTranspose(128, kernel_size=3, strides=2, padding='same')(x)\n    x = LayerNormalization()(x)\n    x = LeakyReLU(0.2)(x)\n\n    # 32x32 -> 64x64\n    x = Conv2DTranspose(64, kernel_size=3, strides=2, padding='same')(x)\n    x = LeakyReLU(0.2)(x)\n\n    # Salida 64x64x3 en rango [-1, 1]\n    out = layers.Conv2D(channels, kernel_size=3, padding='same', activation='tanh')(x)\n\n    return keras.Model(z, out, name=\"Generator\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T11:34:25.413663Z","iopub.execute_input":"2025-10-26T11:34:25.413844Z","iopub.status.idle":"2025-10-26T11:34:25.422980Z","shell.execute_reply.started":"2025-10-26T11:34:25.413828Z","shell.execute_reply":"2025-10-26T11:34:25.422400Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def residual_block(x, filters, upsample=False):\n    shortcut = x\n\n    if upsample:\n        # Upsample input and shortcut\n        x = Conv2DTranspose(filters, kernel_size=3, strides=2, padding='same')(x)\n        shortcut = Conv2DTranspose(filters, kernel_size=1, strides=2, padding='same')(shortcut)\n    else:\n        x = Conv2D(filters, kernel_size=3, padding='same')(x)\n\n    x = BatchNormalization()(x)\n    x = LeakyReLU(0.2)(x)\n\n    x = Conv2D(filters, kernel_size=3, padding='same')(x)\n\n    # Match shortcut shape if needed\n    if not upsample and shortcut.shape[-1] != filters:\n        shortcut = Conv2D(filters, kernel_size=1, padding='same')(shortcut)\n\n    x = Add()([x, shortcut])\n    x = LeakyReLU(0.2)(x)\n    return x\n\ndef build_megaGenerator(latent_dim=100, channels=3):\n    z = Input(shape=(latent_dim,), name=\"latent_vector\")\n\n    x = Dense(1024 * 4 * 4)(z)\n    x = Reshape((4, 4, 1024))(x)\n    x = LeakyReLU(0.1)(x)\n\n    # 4x4 → 8x8 (residual upsample)\n    x = residual_block(x, 512, upsample=True)\n\n    # 8x8 → 16x16 (normal upsample)\n    x = Conv2DTranspose(256, kernel_size=3, strides=2, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(0.1)(x)\n\n    # 16x16 → 32x32 (residual upsample)\n    x = residual_block(x, 128, upsample=True)\n\n    # 32x32 → 64x64 (normal upsample)\n    x = Conv2DTranspose(64, kernel_size=3, strides=2, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(0.1)(x)\n\n    # Output layer\n    out = Conv2D(channels, kernel_size=3, padding='same', activation='tanh')(x)\n\n    return keras.Model(z, out, name=\"Generator\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T11:53:04.411280Z","iopub.execute_input":"2025-10-26T11:53:04.411995Z","iopub.status.idle":"2025-10-26T11:53:04.425212Z","shell.execute_reply.started":"2025-10-26T11:53:04.411974Z","shell.execute_reply":"2025-10-26T11:53:04.424332Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We define the autoencoder, encoder and decoder","metadata":{}},{"cell_type":"code","source":"if folder == None:\n    generator = build_megaGenerator()\n    discriminator = build_discriminator()\nelse:\n    generator = keras.models.load_model(folder + \"Generator.keras\")\n    discriminator = keras.models.load_model(folder + \"Discrimiator.keras\")\ngenerator.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T11:58:52.649391Z","iopub.execute_input":"2025-10-26T11:58:52.649704Z","iopub.status.idle":"2025-10-26T11:58:52.838335Z","shell.execute_reply.started":"2025-10-26T11:58:52.649683Z","shell.execute_reply":"2025-10-26T11:58:52.837524Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ImageDataGenerator\n\nTo fit with the competition, we will reshape images to 64x64","metadata":{}},{"cell_type":"code","source":"# Función personalizada para escalar entre -1 y 1\ndef scale_minus1_to_1(img):\n    return img / 127.5 - 1.0\n\ndatagen = ImageDataGenerator(preprocessing_function=scale_minus1_to_1)\n\ntrain_generator = datagen.flow_from_directory(\n    image_dir,\n    target_size=(height, width),\n    batch_size=batch_size,\n    class_mode='input',\n    subset='training',\n    shuffle=True\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T11:34:27.770661Z","iopub.execute_input":"2025-10-26T11:34:27.770908Z","iopub.status.idle":"2025-10-26T11:36:10.577230Z","shell.execute_reply.started":"2025-10-26T11:34:27.770891Z","shell.execute_reply":"2025-10-26T11:36:10.576295Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"# Compilar discriminador con binary_crossentropy\nopt_d = keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5)\nopt_g = keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5)\ndiscriminator.trainable = True\ndiscriminator.compile(optimizer=opt_d, loss='binary_crossentropy', metrics=['accuracy'])\n\n# Congelar discriminador para entrenar el generador\ndiscriminator.trainable = False\ngan_input = tf.keras.layers.Input(shape=(latent_dim_size,))\ngan_output = discriminator(generator(gan_input))\ngan = tf.keras.Model(gan_input, gan_output)\ngan.compile(optimizer=opt_g, loss='binary_crossentropy')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T11:58:55.183258Z","iopub.execute_input":"2025-10-26T11:58:55.183954Z","iopub.status.idle":"2025-10-26T11:58:55.200505Z","shell.execute_reply.started":"2025-10-26T11:58:55.183931Z","shell.execute_reply":"2025-10-26T11:58:55.199879Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epochs = 10000\n\n# Bucle de entrenamiento\nfor epoch in range(epochs):\n    # === Entrenar discriminador ===\n    # 1. Obtener imágenes reales del generador\n    real_images = next(train_generator)[0]\n\n    # 2. Generar imágenes falsas\n    z = generateLatentDim()\n    fake_images = generator(z, training=False)\n\n    # 3. Crear etiquetas: 1 para reales, 0 para falsas\n    real_labels = np.ones((real_images.shape[0], 1))\n    fake_labels = np.zeros((fake_images.shape[0], 1))\n\n    # # 4. Combinar y mezclar\n    # combined_images = np.concatenate([real_images, fake_images], axis=0)\n    # combined_labels = np.concatenate([real_labels, fake_labels], axis=0)\n\n    # indices = np.arange(combined_images.shape[0])\n    # np.random.shuffle(indices)\n\n    # shuffled_images = combined_images[indices]\n    # shuffled_labels = combined_labels[indices]\n\n    # 5. Entrenar discriminador con batch mezclado (solo una de cada 2)\n    # discriminator.trainable = True\n    # d_loss = discriminator.train_on_batch(shuffled_images, shuffled_labels)\n    if epoch % 3 == 0:\n        discriminator.trainable = True\n        d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n        d_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n\n    # === Entrenar generador ===\n    z = generateLatentDim()\n    trick_labels = np.ones((batch_size, 1))  # queremos que el discriminador crea que son reales\n    discriminator.trainable = False\n    g_loss = gan.train_on_batch(z, trick_labels)\n\n    # Mostrar progreso\n    if epoch % 200 == 0:\n        print(f\"Epoch {epoch} | D loss: {d_loss[0]:.4f} | D acc: {d_loss[1]:.4f} | G loss: {g_loss:.4f}\")\n        mostrar_imagenes_generadas(generator)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T11:58:56.110669Z","iopub.execute_input":"2025-10-26T11:58:56.111326Z","iopub.status.idle":"2025-10-26T12:10:31.902699Z","shell.execute_reply.started":"2025-10-26T11:58:56.111302Z","shell.execute_reply":"2025-10-26T12:10:31.901527Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Comprobar resultados","metadata":{}},{"cell_type":"code","source":"mostrar_imagenes_generadas(generator)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T12:10:43.190258Z","iopub.execute_input":"2025-10-26T12:10:43.190556Z","iopub.status.idle":"2025-10-26T12:10:43.387333Z","shell.execute_reply.started":"2025-10-26T12:10:43.190536Z","shell.execute_reply":"2025-10-26T12:10:43.386647Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Current timestamp\ntimestamp = datetime.datetime.now().strftime(\"%m_%d_%H:%M\")\n## Make sure everything saves correctly\nos.makedirs(\"models\", exist_ok=True)\nos.makedirs(\"models/\"+timestamp, exist_ok=True)\ngenerator_path = f\"models/{timestamp}/Generator.keras\"\ndiscriminator_path = f\"models/{timestamp}/Discrimiator.keras\"\n\n# Save the model\ngenerator.save(generator_path)\ndiscriminator.save(discriminator_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T11:52:42.271933Z","iopub.status.idle":"2025-10-26T11:52:42.272263Z","shell.execute_reply.started":"2025-10-26T11:52:42.272086Z","shell.execute_reply":"2025-10-26T11:52:42.272101Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def guardar_imagenes_en_csv(imagenes_grises):\n    \"\"\"\n    Guarda imágenes en escala de grises en un CSV con columnas: id, 0, ..., 4095.\n\n    Args:\n        imagenes_grises: array de forma (200, 64, 64) con imágenes en escala de grises.\n        nombre_csv: nombre del archivo CSV a guardar.\n    \"\"\"\n    num_imagenes = imagenes_grises.shape[0]\n    pixeles_por_imagen = imagenes_grises.shape[1] * imagenes_grises.shape[2]\n\n    # Aplanar cada imagen a un vector de 4096 elementos\n    imagenes_aplanadas = imagenes_grises.reshape(num_imagenes, pixeles_por_imagen)\n\n    # Crear DataFrame con columnas: id, 0, ..., 4095\n    columnas = ['id'] + [str(i) for i in range(pixeles_por_imagen)]\n    datos = np.column_stack((np.arange(1, num_imagenes + 1), imagenes_aplanadas))\n    df = pd.DataFrame(datos, columns=columnas)\n\n    # Guardar en CSV\n    os.makedirs(\"submissions\", exist_ok=True)\n    timestamp = datetime.datetime.now().strftime(\"%m_%d_%H:%M\")\n    df.to_csv(\"submissions/GAN_\"+timestamp+\".csv\", index=False)\n\n\nguardar_imagenes_en_csv(generar_imagenes(generator, num_imagenes=200))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-26T11:52:42.273557Z","iopub.status.idle":"2025-10-26T11:52:42.273766Z","shell.execute_reply.started":"2025-10-26T11:52:42.273669Z","shell.execute_reply":"2025-10-26T11:52:42.273677Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}