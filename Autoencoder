{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":737475,"sourceType":"datasetVersion","datasetId":379764}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport datetime\nimport pandas as pd\n\nfrom matplotlib import pyplot as plt\n\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Conv2DTranspose, Reshape\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.optimizers import Adam\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_losses(history):\n    plt.rcParams['figure.figsize'] = [20, 5]\n    f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n\n    ax1.set_title('Losses')\n    ax1.set_xlabel('epoch')\n    ax1.legend(loc=\"upper right\")\n    ax1.grid()\n    ax1.plot(history['loss'], label='Training loss')\n    ax1.plot(history['val_loss'], label='Validation loss')\n    ax1.legend()\n\n    ax2.set_title('Accuracy')\n    ax2.set_xlabel('epoch')\n    ax2.legend(loc=\"upper right\")\n    ax2.grid()\n    ax2.plot(history['accuracy'], label='Training accuracy')\n    ax2.plot(history['val_accuracy'], label='Validation accuracy')\n    ax2.legend()\n\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T13:47:39.807247Z","iopub.execute_input":"2025-10-06T13:47:39.807794Z","iopub.status.idle":"2025-10-06T13:47:39.813328Z","shell.execute_reply.started":"2025-10-06T13:47:39.807767Z","shell.execute_reply":"2025-10-06T13:47:39.812486Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Image analysis\n\nWe plot some of the images","metadata":{}},{"cell_type":"code","source":"image_dir = '/kaggle/input/animefacedataset/images'\n\n# Load image file paths\nimage_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir)]\n\n# Read images and collect their shapes\nimages = []\nshapes = []\nfor file in image_files:\n    img = cv2.imread(file)\n    if img is not None:\n        images.append(img)\n        shapes.append(img.shape)\n\n# Check if all shapes are the same\nall_same_shape = all(shape == shapes[0] for shape in shapes)\nprint(\"All images same shape:\", all_same_shape)\nprint(\"Image shape (height, width, channels):\", shapes[0])\n\n# Plot the first 4 images\nfig, axs = plt.subplots(1, 4, figsize=(16, 4))\nfor i in range(min(4, len(images))):\n    img_rgb = cv2.cvtColor(images[i], cv2.COLOR_BGR2RGB)\n    axs[i].imshow(img_rgb)\n    axs[i].axis('off')\n    axs[i].set_title(f'Image {i+1}')\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T13:47:39.815062Z","iopub.execute_input":"2025-10-06T13:47:39.815276Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# pd.Series(shapes).value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Shapes.value_counts()\n```\n(92, 92, 3)      1636\n(96, 96, 3)      1556\n(94, 94, 3)      1534\n(95, 95, 3)      1530\n(90, 90, 3)      1516\n                 ... \n(87, 88, 3)         1\n(220, 220, 3)       1\n(126, 127, 3)       1\n(101, 102, 3)       1\n(181, 181, 3)       1\nName: count, Length: 181, dtype: int64\n```","metadata":{}},{"cell_type":"markdown","source":"# Autoencoder","metadata":{}},{"cell_type":"markdown","source":"## Defining Hiperparameters","metadata":{}},{"cell_type":"code","source":"height, width = 64, 64 # Image size, to fit in the competition size\nimage_dir = '/kaggle/input/animefacedataset'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input_img = keras.Input(shape=(height, width, 3))\n\n# Encoder\nx_enc = Conv2D(16, (3, 3), activation=\"relu\", strides=2, padding=\"same\")(input_img)\nx_enc = Conv2D(32, (3, 3), activation=\"relu\", strides=2, padding=\"same\")(x_enc)\nx_enc = Conv2D(64, (3, 3), activation=\"relu\", strides=2, padding=\"same\")(x_enc)\nx_enc = Conv2D(128, (3, 3), activation=\"relu\", strides=2, padding=\"same\")(x_enc)\nx_enc = Conv2D(128, (3, 3), activation=\"relu\", strides=2, padding=\"same\")(x_enc)\nx_enc = Conv2D(256, (3, 3), activation=\"relu\", strides=2, padding=\"same\")(x_enc)\nshape_before_flattening = keras.backend.int_shape(x_enc)[1:]  # Save shape for reshaping later\nx_enc = Flatten()(x_enc)\nx_enc = Dense(128, activation=\"relu\")(x_enc)\nx_enc = Dense(64, activation=\"relu\")(x_enc)\nencoded = Dense(32, activation=\"relu\")(x_enc)\n\n# Decoder\nx_dec = Dense(64, activation=\"relu\")(encoded)\nx_dec = Dense(128, activation=\"relu\")(x_dec)\nx_dec = Dense(np.prod(shape_before_flattening), activation=\"relu\")(x_dec)\nx_dec = Reshape(shape_before_flattening)(x_dec)\nx_dec = Conv2DTranspose(256, (3, 3), activation=\"relu\", strides=2, padding=\"same\")(x_dec)\nx_dec = Conv2DTranspose(128, (3, 3), activation=\"relu\", strides=2, padding=\"same\")(x_dec)\nx_dec = Conv2DTranspose(128, (3, 3), activation=\"relu\", strides=2, padding=\"same\")(x_dec)\nx_dec = Conv2DTranspose(64, (3, 3), activation=\"relu\", strides=2, padding=\"same\")(x_dec)\nx_dec = Conv2DTranspose(32, (3, 3), activation=\"relu\", strides=2, padding=\"same\")(x_dec)\nx_dec = Conv2DTranspose(16, (3, 3), activation=\"relu\", strides=2, padding=\"same\")(x_dec)\ndecoded = Conv2D(3, (3, 3), activation=\"sigmoid\", padding=\"same\")(x_dec)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We define the autoencoder, encoder and decoder","metadata":{}},{"cell_type":"code","source":"autoencoder = keras.Model(input_img, decoded)\nencoder = keras.Model(input_img, encoded)\ndecoder = keras.Model(encoded, decoded)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=1e-3)\nautoencoder.compile(optimizer=opt, loss=\"binary_crossentropy\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ImageDataGenerator\n\nTo fit with the competition, we will reshape images to 64x64","metadata":{}},{"cell_type":"code","source":"datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n\n# Create training and validation generators using the same seed\ntrain_generator = datagen.flow_from_directory(\n    image_dir,\n    target_size=(height, width),  \n    batch_size=256,\n    class_mode='input',\n    subset='training',\n    shuffle=True,\n    seed=2004  \n)\n\nval_generator = datagen.flow_from_directory(\n    image_dir,\n    target_size=(height, width),\n    batch_size=256,\n    class_mode='input',\n    subset='validation',\n    shuffle=False,\n    seed=2004\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"# Fit the autoencoder\nh = autoencoder.fit(\n    train_generator,\n    epochs=2,\n    validation_data=val_generator\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_losses(h.history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Current timestamp\ntimestamp = datetime.datetime.now().strftime(\"%m_%d_%H:%M\")\n## Make sure everything saves correctly\nos.makedirs(\"models\", exist_ok=True)\n\nmodel_path = f\"models/autoencoder_{timestamp}.keras\"\n\n# Save the model\nmodel.save(model_path)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}